<!DOCTYPE html>
<html lang="en-us"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
   
    <meta name="description" content="
This page contains some teasers of the project I&#39;m working on. Below I will show some screenshots, general plans, and resources that will contribute to the project. Likewise, I will share my current &#34;blockages&#34;.


Notes and Thoughts
I think I&rsquo;ll overall need to consult with people on how to approach this massive of a data analysis. I&rsquo;ve done smaller web-scraping analyses before, but this is an enormous project.
A) Use Apache Spark for Pol Research because it is designed to handle very large data sets. I don&rsquo;t have the RAM to do everything at once. However, I do have the CSV files for doing one-at-a-time analysis that I can export, and later compile for total analysis in R.">  
  

  <title>
    
      Politically Incorrect (4Chan) Ethnogaphy
    
  </title>

  <link rel="shortcut icon" type="image/x-icon" href="/" />
  
  
  <link rel="stylesheet" href="/css/unified.css" />

  
</head>
<body a="auto">
    <div class="bg-img">
      <div class="container">
        <div class="topnav">
          <a href="/index.html">Home</a>
          <a href="/resume/index.html">Resume</a>
          <a href="/projects/index.html">Projects</a>
          <br>
          <a href="/hobbies/index.html">Hobbies</a>
          <a href="/robert-moore-public-GPG.asc">PGP Key</a>
          <a href="/experience/index.html">Experience</a>
          <br>
          <a href="/essays/index.html">Essays</a>
          <a href="/guides/index.html">Guides</a>
        </div>
      </div>
    </div>
        <main class="page-content" aria-label="Content">
            <div class="w">



<article>
    <p class="post-meta">
       
    </p>

    <h1>Politically Incorrect (4Chan) Ethnogaphy</h1>

    

    <p class="description">
This page contains some teasers of the project I'm working on. Below I will show some screenshots, general plans, and resources that will contribute to the project. Likewise, I will share my current "blockages".
</p>
<hr>
<h1 id="notes-and-thoughts">Notes and Thoughts</h1>
<p>I think I&rsquo;ll overall need to consult with people on how to approach this massive of a data analysis. I&rsquo;ve done smaller web-scraping analyses before, but this is an enormous project.</p>
<p>A) Use <code>Apache Spark</code> for Pol Research because it is designed to handle very large data sets. I don&rsquo;t have the RAM to do everything at once. However, I do have the CSV files for doing one-at-a-time analysis that I can export, and later compile for total analysis in <code>R</code>.</p>
<p>B) If 4chan closes, it will cause a lot of social problems because Pennebaker showed that writing about your problems, which is tantamount to 4chan posting, reduces behavioral upsets.</p>
<p>C) Perhaps I can put the CSV files into a PostgreSQL database and have <code>R</code> access that as a source instead of CSV?</p>
<p>D) I will probably have to ignore time as a factor and I can fakename dates as something like &ldquo;per million rows, this was the most common topic&rdquo; which is arbitrary but big enough to form a pattern since I have ~1200 files.</p>
<p>E) Possible Solutions: <strong>1)</strong> Perhaps my GPU is stronger than my CPU and I can use that?; <strong>2)</strong> CORS between server and desktop?; <strong>3)</strong> After I write the code based on samples, maybe I can rent a big server through a tech company?; <strong>4)</strong> Ask around on the R or JupyterLab forums to ask what the best approach to huge data analysis is.</p>
<p>F) What could this analysis show me? <strong>1)</strong> Current declared beliefs can act as a filter for how current popular beliefs gained a foothold. There&rsquo;s research on that, anyway. The number is disputed, but roughly 10% to 25% of a population needs to radically hold a belief to shift others into believing; <strong>2)</strong> How does text content change over time? What persists over time? How can this be leveraged for understanding online culture?</p>
<p>G) Need to figure out how to make an R based survey. Maybe hostable on github or something for free? I don&rsquo;t want these guys having my IP or anything.</p>
<p>H) Ask people to fill out surveys on beliefs and cross that data with text analysis?</p>
<h1 id="workflow-for-archive-only-data-gathering">Workflow for Archive-Only Data Gathering</h1>
<center>
<embed src="/photos/wget-archive-pol.png" width="100%" frameborder="30px"></embed>
</center>
<p>Above is the process used for downloading the <em>4plebs</em> archive that is stored on <a href="https://archive.org">The Internet Archive.</a> <code>wget</code> is a package commonly found on all Linux systems. The total tar archive downloaded was 42.4 Gb, and after running <code>tar xf</code> on the file, the expanded data resulted in 130 Gb. Unfortunately, this is one of the blockages I was speaking about before. I&rsquo;m unable to input 130 Gb of data into R-Studio (Posit). For me to contain that data in my memory (RAM), I&rsquo;d need to exceed 130 Gb of RAM.</p>
<p>Though, there is another work around which is that I break up the data stored in CSV format. Below, you can see some code that I used to split up the enormous CSV file of 130 Gb into 1266 files with 1,000,000 obersations each. This project would roughly contain 1.3 trillion observations that would need to be tokenized.</p>
<pre tabindex="0"><code>#!/bin/bash
split -l 1000000 -d â€”additional-suffix=.csv pol.csv pol
# Use split to..
# choose lines start-1,000,000
# -d add a number at the end
# --additional-suffix = ass .csv suffix
# use pol.csv
# name the new file pol{&lt;number&gt;}.csv
</code></pre><p>The screenshot below displays some sample output from one of the CSV files which would still need to be cleaned up. Using the <code>tidyverse</code> I am able to remove the numbers, and symbols, so that I can reduce my total tokens for analysis.</p>
<center>
<embed src="/photos/csv-preview.png" width="100%" frameborder="30px"></embed>
</center>
<h1 id="ethnography-notes-rstudio-videos-and-texts">Ethnography Notes: Rstudio Videos, and Texts</h1>
<p><a href="https://tensorflow.rstudio.com/tutorials/keras/text_classification.html">https://tensorflow.rstudio.com/tutorials/keras/text_classification.html</a></p>
<p><a href="https://bookdown.org/yihui/rmarkdown-cookbook/eng-bash.html">https://bookdown.org/yihui/rmarkdown-cookbook/eng-bash.html</a></p>
<ul>
<li>Data Professor <a href="https://www.youtube.com/watch?v=dRqtLxZVRuw">https://www.youtube.com/watch?v=dRqtLxZVRuw</a></li>
<li>R - Install R on USB: <a href="https://www.youtube.com/watch?v=earYvB_nRi4">https://www.youtube.com/watch?v=earYvB_nRi4</a></li>
<li>R - Layout: <a href="https://www.youtube.com/watch?v=FafxYUnIaOM">https://www.youtube.com/watch?v=FafxYUnIaOM</a></li>
<li>R - Calculator on Steroids: <a href="https://www.youtube.com/watch?v=E0WZrR8_WGA">https://www.youtube.com/watch?v=E0WZrR8_WGA</a></li>
<li>R - Install R packages from CRAN: <a href="https://www.youtube.com/watch?v=qe0Rx48uF8w">https://www.youtube.com/watch?v=qe0Rx48uF8w</a></li>
<li>R - Saving and Closing R: <a href="https://www.youtube.com/watch?v=XfuaczpN_Do">https://www.youtube.com/watch?v=XfuaczpN_Do</a></li>
<li>R - Data Structures (part 1) - vectors and factors: <a href="https://www.youtube.com/watch?v=kL0-k_NrIls">https://www.youtube.com/watch?v=kL0-k_NrIls</a></li>
<li>R - Data Structures (part 2) - data frames: <a href="https://www.youtube.com/watch?v=WedM1kG9LLA">https://www.youtube.com/watch?v=WedM1kG9LLA</a></li>
<li>Importing Data in R - alternative easier method: <a href="https://www.youtube.com/watch?v=yy-LTLw2Ey4">https://www.youtube.com/watch?v=yy-LTLw2Ey4</a></li>
<li>R - Exploring Data (part 1) - Import data in R: <a href="https://www.youtube.com/watch?v=dJEhINzZOaw">https://www.youtube.com/watch?v=dJEhINzZOaw</a></li>
<li>R - Exploring Data (part 2) - Extraction &amp; Transformation: <a href="https://www.youtube.com/watch?v=v11SWrC6qGk">https://www.youtube.com/watch?v=v11SWrC6qGk</a></li>
<li>R - Exploring Data (part 3) - Univariate Summaries: <a href="https://www.youtube.com/watch?v=EVmuPZgTf2U">https://www.youtube.com/watch?v=EVmuPZgTf2U</a></li>
<li>R - Aggregate function: <a href="https://www.youtube.com/watch?v=sqIYGUk9jc0">https://www.youtube.com/watch?v=sqIYGUk9jc0</a></li>
<li>R - Exploring Data (part 4) - Bivariate Summaries: <a href="https://www.youtube.com/watch?v=BnBW2CUD0-A">https://www.youtube.com/watch?v=BnBW2CUD0-A</a></li>
<li>R - Exploring Data (part 5) - Multivariate Summaries: <a href="https://www.youtube.com/watch?v=23AT9m1HkOI">https://www.youtube.com/watch?v=23AT9m1HkOI</a></li>
<li>R - Simple Linear Regression (part 1): <a href="https://www.youtube.com/watch?v=wnIlld_8lSg">https://www.youtube.com/watch?v=wnIlld_8lSg</a></li>
<li>R - Simple Linear Regression (part 2): <a href="https://www.youtube.com/watch?v=m_8XYVzT1IU">https://www.youtube.com/watch?v=m_8XYVzT1IU</a></li>
<li>R Square - clearly explained (part 1): <a href="https://www.youtube.com/watch?v=iCmA5w_YOmo">https://www.youtube.com/watch?v=iCmA5w_YOmo</a></li>
<li>R Square - clearly explained (part 2): <a href="https://www.youtube.com/watch?v=t9u5kty3b0Q">https://www.youtube.com/watch?v=t9u5kty3b0Q</a></li>
<li>R - Multiple Regression (part 1): <a href="https://www.youtube.com/watch?v=kl4RxV37ebk">https://www.youtube.com/watch?v=kl4RxV37ebk</a></li>
<li>R - Multiple Regression (part 2): <a href="https://www.youtube.com/watch?v=exwJHLHY9Hw">https://www.youtube.com/watch?v=exwJHLHY9Hw</a></li>
<li>R - Multiple Regression (part 3): <a href="https://www.youtube.com/watch?v=tvgif3X6an0">https://www.youtube.com/watch?v=tvgif3X6an0</a></li>
<li>kNN Machine Learning Algorithm - Excel: <a href="https://www.youtube.com/watch?v=x69YhAapw4k">https://www.youtube.com/watch?v=x69YhAapw4k</a></li>
<li>R - kNN - k nearest neighbor (part 1): <a href="https://www.youtube.com/watch?v=GtgJEVxl7DY">https://www.youtube.com/watch?v=GtgJEVxl7DY</a></li>
<li>R - kNN - k nearest neighbor (part 2): <a href="https://www.youtube.com/watch?v=DkLNb0CXw84">https://www.youtube.com/watch?v=DkLNb0CXw84</a></li>
<li>CART Tree Basics: <a href="https://www.youtube.com/watch?v=MmPmnQNEmQE">https://www.youtube.com/watch?v=MmPmnQNEmQE</a></li>
<li>R - Classification Trees (part 1 using C5.0): <a href="https://www.youtube.com/watch?v=5NquIfQxpxk">https://www.youtube.com/watch?v=5NquIfQxpxk</a></li>
<li>R - Classification Trees (part 2 using rpart): <a href="https://www.youtube.com/watch?v=XLNsl1Da5MA">https://www.youtube.com/watch?v=XLNsl1Da5MA</a></li>
<li>R - Regression Trees - CART: <a href="https://www.youtube.com/watch?v=MoBw5PiW56k">https://www.youtube.com/watch?v=MoBw5PiW56k</a></li>
<li>CART Regression Trees Algorithm - Excel part 1: <a href="https://www.youtube.com/watch?v=nWuUahhK3Oc">https://www.youtube.com/watch?v=nWuUahhK3Oc</a></li>
<li>CART Regression Trees Algorithm - Excel part 2: <a href="https://www.youtube.com/watch?v=IQe2Icb1WKE">https://www.youtube.com/watch?v=IQe2Icb1WKE</a></li>
<li>R - Association Rules - Market Basket Analysis (part 1): <a href="https://www.youtube.com/watch?v=b5hgDPa7a2k">https://www.youtube.com/watch?v=b5hgDPa7a2k</a></li>
<li>R - Association Rules - Market Basket Analysis (part 2): <a href="https://www.youtube.com/watch?v=Gy_nqzJMNrI">https://www.youtube.com/watch?v=Gy_nqzJMNrI</a></li>
<li>R - Twitter Mining with R (part 1): <a href="https://www.youtube.com/watch?v=lT4Kosc_ers">https://www.youtube.com/watch?v=lT4Kosc_ers</a></li>
<li>R - Twitter Mining with R (part 2) create WordCloud from Tweets: <a href="https://www.youtube.com/watch?v=JoArGkOpeU0">https://www.youtube.com/watch?v=JoArGkOpeU0</a></li>
<li>Text Mining (part 1) - Import Text into R (single document): <a href="https://www.youtube.com/watch?v=fga5gLtFQs0">https://www.youtube.com/watch?v=fga5gLtFQs0</a></li>
<li>Text Mining (part 2) - Cleaning Text Data in R (single document): <a href="https://www.youtube.com/watch?v=gtQWMxWzs_M">https://www.youtube.com/watch?v=gtQWMxWzs_M</a></li>
<li>Text Mining (part 3) - Sentiment Analysis and Wordcloud in R (single document): <a href="https://www.youtube.com/watch?v=JM_J7ufS-BU">https://www.youtube.com/watch?v=JM_J7ufS-BU</a></li>
<li>Text Mining (part4) - Postive and Negative Terms for Sentiment Analysis in R: <a href="https://www.youtube.com/watch?v=WfoVINuxIJA">https://www.youtube.com/watch?v=WfoVINuxIJA</a></li>
<li>Text Mining (part 5) - Import a Corpus in R: <a href="https://www.youtube.com/watch?v=pFinlXYLZ-A">https://www.youtube.com/watch?v=pFinlXYLZ-A</a></li>
<li>Text Mining (part 6) - Cleaning Corpus text in R: <a href="https://www.youtube.com/watch?v=jCrQYOsAcv4">https://www.youtube.com/watch?v=jCrQYOsAcv4</a></li>
<li>Text Mining (part 7) - Comparison Wordcloud in R: <a href="https://www.youtube.com/watch?v=pvjhm5TTd2A">https://www.youtube.com/watch?v=pvjhm5TTd2A</a></li>
<li>Text Mining (part 8) - Sentiment Analysis on Corpus in R: <a href="https://www.youtube.com/watch?v=jt4WzWoSCyo">https://www.youtube.com/watch?v=jt4WzWoSCyo</a></li>
<li>Rmarkdown - Introduction and Basics: <a href="https://www.youtube.com/watch?v=tKUufzpoHDE">https://www.youtube.com/watch?v=tKUufzpoHDE</a></li>
<li>R - run R non-interactively with BATCH file: <a href="https://www.youtube.com/watch?v=Guw2XgGvl44">https://www.youtube.com/watch?v=Guw2XgGvl44</a></li>
<li>Create Training and Test data in R: <a href="https://www.youtube.com/watch?v=nXIzNAa4mFo">https://www.youtube.com/watch?v=nXIzNAa4mFo</a></li>
<li>RStudio Cloud - upload data set: <a href="https://www.youtube.com/watch?v=-tQDr4kzAGY">https://www.youtube.com/watch?v=-tQDr4kzAGY</a></li>
<li>R - Mac getting started part 1: <a href="https://www.youtube.com/watch?v=6XGI-2RDa7Y">https://www.youtube.com/watch?v=6XGI-2RDa7Y</a></li>
<li>R - Mac getting started part 2: <a href="https://www.youtube.com/watch?v=SEg75c4hS64">https://www.youtube.com/watch?v=SEg75c4hS64</a></li>
<li>R - import data, save history, getting started in R: <a href="https://www.youtube.com/watch?v=XZN910MLiyQ">https://www.youtube.com/watch?v=XZN910MLiyQ</a></li>
<li>R - saving and restarting where you left off: <a href="https://www.youtube.com/watch?v=N1gOuvGkGBk">https://www.youtube.com/watch?v=N1gOuvGkGBk</a></li>
</ul>

</article>

                
    
    
        
    


            </div>
        </main>
        <div class="image3"> 
        <img src="/css/quil.png" alt="psyquil" width="auto">
        </div>
    </body>
</html>


